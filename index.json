[{"content":" In behavioural ecology, animal social networks are used to answer a wide variety of questions. However, unlike in the analysis of human social networks, we can’t ask animals what their social preferences are. Instead we have to estimate them based on observable events like spatial associations or interactions. This means we can never be fully certain in the estimated social preferences, and if very few observations are made, it is possible that the estimated social preferences could be quite inaccurate. We recently wrote a paper to tackle some of these issues.\nBinary and Count Data # Two very common types of data used to build animal social networks are binary data and count data. These are broad classifications that are important in understanding what the edges in social networks really mean. In binary data, observations are collected over a series of fixed sampling periods. Observations are simply the binary presence or absence of social events within each sampling period. The number of observed social events between a pair of individuals is \\(X\\), and the number of sampling periods where a social event could have been observed between the pair is \\(D\\). Network edges are calculated as the simple ratio index (SRI), which is defined as \\(\\text{SRI}\\) = \\(X/D\\). This means that the SRI is equivalent to the probability of seeing a social event in a randomly-selected sampling period.\nCount data is where the count of social events that were observed between two individuals is recorded over the amount of time that a social event could have been observed between them. This type of data is usually used to build social networks by dividing the count by the time, giving the rate of social events occurring per unit time. Again we use the SRI to quantify edge weights for this type of data, where X is the count of social events, and D is the total amount of time spent observing at least one of the two individuals.\nIn both of these types of data, we assume that the SRI is a useful estimate of the underlying social preference. This assumption is equivalent to assuming that in binary data, the count \\(X\\) is a draw from a binomial process with \\(D\\) trials and success probability equal to the SRI; and that in count data, the count \\(X\\) is a draw from a Poisson process with rate equal to \\(D \\times \\text{SRI}\\). Using these statistical processes to model binary and count data, we can estimate how accurate our estimated social networks are without making any additional assumptions than those already made when calculating the SRI.\nNormalised probability distribution of SRI values for different amounts of time spent sampling. Under a lower sampling time, the probability distribution is much wider than the higher sampling case. In both cases the true SRI is 2. This shows that the amount of time spent sampling will impact the accuracy of estimated SRI values.\nAccuracy of Social Networks # This problem was recognised by Whitehead (2008), which developed a method to estimate the accuracy of social networks constructed from binary data [2]. In our new paper, we have extended this method to count data [1].\nThe key notion behind the method is that the dissimilarity between the estimated social preference (SRI) and the underlying social preference will reduce towards zero as sampling \\(D\\) increases. As a result, the correlation between the estimated and underlying social preference is a good measure of the accuracy of the social network. This allows us to calculate the correlation between estimated and underlying social preference in terms of the ratio of variances for the estimated and underlying social preferences (see our paper for full details).\nThe full details can be found in the original papers, but in short, Whitehead found that the accuracy of social networks constructed from binary data can be estimated using the following equation:\n$$ \\hat{\\rho}_\\text{binary} =\\frac{1}{\\sqrt{1 + \\frac{1}{S^2 G}}} $$\nwhere \\(S\\) is the coefficient of variation of social preferences (often referred to as social differentiation) and G is the mean number of observed social events per dyad.\nFor count data, we found in our paper that the accuracy of social networks constructed from this kind of data can be estimated by:\n$$ \\hat{\\rho}_\\text{count} = \\frac{S \\sqrt{\\mu H(D)}}{\\sqrt{1 + S^2 \\mu H(D)}} $$\nwhere S is again social differentiation, \\(\\mu\\) is the mean rate of social events over all dyads in the networks, and \\(H(D)\\) is the harmonic mean of the sampling times of all dyads in the network.\nThese two equations can provide useful estimates of how representative a estimated social network is of its underlying social network, and can have consequences on the power of subsequent statistical analyses. This could be useful for determining whether or not sufficient data have been collected to carry out an analysis, for splitting up data into multiple intervals, or even just to validate the accuracy of networks. If you’d like to know a bit more about this, we explore these ideas further in our paper.\nIf you’re interested in using these methods in your study, for R implementations check out the social_differentiation function in the R package aninet (for binary data), and our R package pwrCGP (for count data). Hal Whitehead’s original code in MATLAB is available in SOCPROG.\nReferences # [1] Hart, J. D., Franks, D. W., Brent, L. J., \u0026amp; Weiss, M. N. (2021). Accuracy and Power Analysis of Social Interaction Networks. Methods in Ecology and Evolution.\n[2] Whitehead, H. (2008). Precision and power in the analysis of social structure using associations. Animal Behaviour.\n","date":"8 August 2021","permalink":"/posts/network_power/","section":"Posts","summary":"In behavioural ecology, animal social networks are used to answer a wide variety of questions.","title":"How Accurate are Inferred Social Networks?"},{"content":"This is a short blog post to complement our paper on non-independence and permutation tests in animal social network analysis. We submitted the paper to a journal last year and had some pretty mixed feedback. We feel there\u0026rsquo;s a lot to unpack in our paper, so to make things more manageable we wanted to release a blog post to coincide with our resubmission to explain again the issues we cover in our paper in bite-sized chunks.\nBefore digging in to the paper, let\u0026rsquo;s start off with some background. Permutations are non-parametric methods based on randomising/permuting data. The key motivation behind permutation methods is that under null hypotheses (e.g. social structure is random or there\u0026rsquo;s no association between age and network centrality), data can be randomised in some way to simulate the null distribution of test statistics. The observed test statistic can then be compared to the null distribution to calculate p-values and conduct null hypothesis significance testing. In the paper we focus on regression scenarios rather than questions about non-randomness of social structure.\nOne of the main justifications for using permutation in network analysis is that they appear to control for non-independence that is assumed to be inherent in network data.\nThere are 3 main messages in our paper:\nPermutations don\u0026rsquo;t control for non-independence.\nIn the type of analyses we\u0026rsquo;re interested in, we don\u0026rsquo;t need to worry about non-independence of network data.\nWe think parametric methods should be used instead of permutations.\nLet\u0026rsquo;s address these messages one at a time.\nPermutations don\u0026rsquo;t control for non-independence # The first main message is quite simple. If data are non-independent, and you can\u0026rsquo;t use standard parametric models because of this, permutations won\u0026rsquo;t be of any use either. This is because permutations make a very similar assumption to parametric models - namely that data points are exchangeable. Exchangeability is an assumption that for practical purposes is nearly identical to independence.\nThis is important because the historical justification for using permutations in network analysis is that they control for the inherent non-independence of network data. However, we showed that if there is inherent non-independence in network data, permutations are in the same boat as parametric models - they don\u0026rsquo;t do anything to control for this non-independence.\nThis might seem really bad, but just how bad is it? Fortunately it turns out this isn\u0026rsquo;t a problem at all. This is because of the type of analysis we\u0026rsquo;re usually doing when using permutations with regression models.\nNetwork-derived non-independence isn\u0026rsquo;t a problem # First let\u0026rsquo;s be clear on what kind of analysis we\u0026rsquo;re talking about here. We focus on regression analyses where either A) the relationships between node metrics and node traits are assessed using a regression analysis, or B) the relationships between dyad metrics and dyad traits are assessed using a regression analysis. Depending on context, non-independence in networks can be a major problem. But in particular, for these two types of analysis, the inherent non-independence of network data isn\u0026rsquo;t a problem.\nTo explain this, assume that X and Y are node metrics and node traits, and we want to regress one against the other, like this: Y ~ X (note: it doesn\u0026rsquo;t matter if the metric is the predictor or response). The question at the heart of this analysis is about the relationship (if any) between Y and X. The relationship between Y and X an emergent property of a complex set of biological and mathematical processes that gives a descriptive insight into how individuals organise within social groups. In an ideal world, there would be no variation in this relationship across the population, but there always is. There are many sources of variation, such as noise in measurement of traits, noise induced by proxy variables, complex intra-individual processes, and more. Fortunately in our analysis, these variations happen at the nodal (or dyadic) level. This means that differences in the relationships between X and Y over the population can be explained by an independent noise term, and that the data can be considered to be independent.\nThis revelation is really important, because it means that an assumption of independence is completely appropriate for this type of analysis. Any additional sources of non-independence like repeated measures will still need to be accounted for, but the apparent non-independence of network data isn\u0026rsquo;t a concern anymore. This means we can use either standard parametric models or permutations to run these kinds of analysis. There are a few additional minor considerations for dyadic regressions, so we recommend reading the paper in full to learn more about the types of non-independence unique to dyadic regression.\nWhere does this leave us? Permutations don\u0026rsquo;t control for non-independence, but they don\u0026rsquo;t need to either. Should we carry on using them then? We think no.\nWe should use parametric models instead of permutations # The previous two messages were purely factual, but this third and final message is just our opinion. So feel free to stop reading here if you really like permutations! But we think it\u0026rsquo;s worth considering using parametric models instead of permutations for a number of reasons. Firstly, at a sociological level, most researchers already use parametric models for non-network data. This means there\u0026rsquo;s virtually no learning curve to using parametric models for network data too. But there are also a number of issues with permutations that we think are compelling reasons to consider retiring them:\nWhen controlling for additional effects in permutations, the main effect size isn't corrected, so it's possible to get incorrect effect sizes (sometimes with the wrong sign) using permutations (Franks et al. 2020).Permutations are reliant on null hypothesis significance testing and p-values, making it difficult to adopt best practices for reliable science (Halsey 2019).It can be easy to test the wrong null hypothesis with permutations (see Weiss et al. 2020).Datastream permutations can have convergence issues (Hart et al. 2022).Permutations are incompatible with Bayesian methods, leaving a whole realm of methodology unavailable to network analysis.Null distributions generated from permutations can be unrepresentative of the true null when sample sizes are small, which could lead to spurious conclusions.Standard diagnostic tests aren't available for permutations so it can be difficult to check assumptions, again leading to potentially spurious results. We have no intention of making anyone use one approach over the other, but we definitely think it\u0026rsquo;s worth considering using parametric models instead.\nWe hope this helps to clear things up a bit. Please do get in touch if you\u0026rsquo;d like to share any of your thoughts with us.\nReferences # Franks, D. W., Weiss, M. N., Silk, M. J., Perryman, R. J., \u0026amp; Croft, D. P. (2020). Calculating effect sizes in animal social network analysis.\nHalsey, L. G. (2019). The reign of the p-value is over: what alternative analyses could we employ to fill the power vacuum?\nWeiss, M. N., Franks, D. W., Brent, L. J., Ellis, S., Silk, M. J., \u0026amp; Croft, D. P. (2020). Common datastream permutations of animal social network data are not appropriate for hypothesis testing using regression models.\nHart, J. D. A., Franks, D. W., Brent, L. J., \u0026amp; Weiss, M. N. (2022). Why datastream permutations need diagnostics.\n","date":"12 March 2022","permalink":"/posts/permutation_problems/","section":"Posts","summary":"This is a short blog post to complement our paper on non-independence and permutation tests in animal social network analysis.","title":"The Problem with Permutations"},{"content":"Statistical tests based on permutations (also called randomisations or resampling) are popular in many fields. In behavioural ecology and animal social network analysis permutations are used to generate reference distributions for a variety of statistical analyses. In particular, Markov chain-like algorithms are often used where samples are highly constrained (e.g. interaction matrices). In a recent tiny preprint we highlight that these permutation algorithms should be used in conjunction with MCMC diagnostics such as multiple chains, R-hat statistics, and effective sample sizes. In a realistic use case we found that nearly half of tests resulted in a false positive.\nRead the preprint here\n","date":"25 August 2022","permalink":"/posts/tiny_steps/","section":"Posts","summary":"Statistical tests based on permutations (also called randomisations or resampling) are popular in many fields.","title":"Tiny Steps, Big Problems"},{"content":"Social networks have become an important tool in behavioural ecology. But unlike other quantities, networks are inferred rather than directly measured. Depending on the way this is done, social networks can have a large uncertainty that previous methods haven\u0026rsquo;t been able to quantify. We have developed a general Bayesian framework that solves this problem and conducts Bayesian social network analysis to make the most of hard-won behavioural data. If you\u0026rsquo;re interested, you can read more about the framework in our preprint and get hands on with BISoN in our R package bisonR.\n","date":"3 October 2022","permalink":"/posts/bison/","section":"Posts","summary":"Social networks have become an important tool in behavioural ecology.","title":"Building Social Networks with BISoN"},{"content":"JAX is a powerful tensor manipulation and autograd library that has seen a surge in popularity recently. It\u0026rsquo;s also one of the key dependencies in Google\u0026rsquo;s neural network library Flax. However, trying to install it on an M1 Mac can be a bit tricky. Today I managed to get it running on a 2021 Macbook Pro M1 without too many problems, so I\u0026rsquo;ve shared the Python environment here to help others facing the same problem. Once downloaded, and in a virtual environment, the key dependencies can be installed by running:\npip install --upgrade pip pip install -r flax-requirements.txt And that should (hopefully) do it.\nOut of curiosity I ran a quick test using a CNN on MNIST to see how well the M1 chip does against a Colab GPU. I ran the example code and recorded how long 10 training and evaluation epochs took with a fixed batch size of 32.\nDevice Running Time M1 Pro (10 Core) 3m 3s Colab GPU 1m 7s Colab CPU ~ 20m My 10 core M1 Pro ran 10 epochs in 3 minutes and 3 seconds, where the Colab GPU took only 1 minute and 7 seconds. Though nearly 3x slower, I don\u0026rsquo;t think this is too bad for a CPU, and will be great for development environments. This story might change a lot depending on batch sizes and workloads, so take this with a pinch of salt. For reference though, a Colab CPU took around 20 minutes to run the same code, so the M1 CPU is certainly doing something right.\nPyMC \u0026amp; BlackJAX # Another reason you might want to use JAX is for probabilistic programming in PyMC. Using a JAX-based backend (BlackJAX) it\u0026rsquo;s possible to speed up model compilation and fitting quite considerably. I also ran a quick comparison using a simple linear regression with 2000 data points to test sampling and compilation times in PyMC and CmdStan. I ran each model 5 times and took the lowest number for both sampling time and end-to-end time, including compilation.\nSampler Sampling Time End-to-end Time CmdStan 2.30.0 1.1s 6.7s PyMC 4.2.2 9.0s 10.9s PyMC 4.2.2 + BlackJAX 2.8s 3.6s PyMC 4.2.2 + NumPyro 1.8s 2.8s Interestingly, base PyMC was slowest in both cases, but benefitted a lot from using the BlackJAX and NumPyro backends. The CmdStan sampler was fastest, but takes a while longer to compile meaning the end-to-end time was slower. This benchmark is far from exhaustive, and depending on model specification and dataset size, I suspect these results could change a lot.\n","date":"19 October 2022","permalink":"/posts/flax_mac/","section":"Posts","summary":"JAX is a powerful tensor manipulation and autograd library that has seen a surge in popularity recently.","title":"Jax, Flax, \u0026 Macs"},{"content":"","date":"19 October 2022","permalink":"/","section":"Jordan Hart","summary":"","title":"Jordan Hart"},{"content":"","date":"19 October 2022","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"I’m a final year PhD student at the Centre for Research in Animal Behaviour at the University of Exeter, UK under the supervision of Lauren Brent and Dan Franks. My academic interests are in using data science to understand complex systems. Specific areas of interest include Bayesian statistics, causal inference, philosophy of science, and deep learning.\nTo see a complete list of my publications, check out my Google Scholar profile.\nI have previously worked in NLP projects, and am interested in bringing these ideas to my future work. I hold a master’s degree in Mathematics from the University of York, UK.\nAs well as my academic work, I also provide consulting services to businesses looking to get the most out of their data. My consulting work largely focuses on analysis of surveys and behavioural data.\nI’m always open to new opportunities to explore these topics. If you’d like to get in touch, please send me an email.\n","date":"14 August 2020","permalink":"/about/","section":"Jordan Hart","summary":"I’m a final year PhD student at the Centre for Research in Animal Behaviour at the University of Exeter, UK under the supervision of Lauren Brent and Dan Franks.","title":"About"},{"content":"This is a list of selected papers. For a full list, check out my Google Scholar profile.\nWhy Datastream Permutations Need Diagnostics\nHart, J. D., Franks, D. W., Brent, L. J., \u0026amp; Weiss, M. N. (2022). OSF Preprints. (Preprint)\nPDF | CODE\nBISoN: A Bayesian Framework for Inference of Social Networks\nHart, J. D., Weiss, M. N., Franks, D. W., \u0026amp; Brent, L. J. (2021). bioRxiv. (Preprint)\nPDF | CODE | R PACKAGE\nCommon Permutation Methods in Animal Social Network Analysis Do Not Control for Non-independence\nHart, J. D., Weiss, M. N., Brent, L. J., \u0026amp; Franks, D. W. (2021). bioRxiv. (Preprint)\nPDF | CODE | R PACKAGE\nAccuracy and Power Analysis of Social Interaction Networks\nHart, J. D., Franks, D. W., Brent, L. J., \u0026amp; Weiss, M. N. (2022). Methods in Ecology and Evolution.\nPDF | CODE\n","date":"14 August 2020","permalink":"/papers/","section":"Jordan Hart","summary":"This is a list of selected papers.","title":"Papers"},{"content":"","date":"1 January 0001","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"1 January 0001","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"}]